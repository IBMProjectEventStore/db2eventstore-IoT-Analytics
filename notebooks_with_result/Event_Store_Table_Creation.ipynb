{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# IBM Db2 Event Store - Table creation\n",
    "IBM Db2 Event Store is a hybrid transactional/analytical processing (HTAP) system that is designed for IoT workloads. It is empowered by the Db2 Common SQL Engine, the most sophisticated SQL-based analytics query engine available. IBM Db2 Event Store can handle complex queries quickly and efficiently.\n",
    "\n",
    "In this lab, you will explore the best practices fro IBM DB2 Event Store. You will learn:\n",
    "- Database creation with IBM DB2 Event Store 2.0\n",
    "- Best practices for table definition\n",
    "- Best practices for indexing a table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import event store's Python client interface libraries\n",
    "from eventstore.oltp import EventContext\n",
    "from eventstore.sql import EventSession\n",
    "from pyspark.sql import SparkSession\n",
    "from eventstore.common import ConfigurationReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"connect-to-es\"></a>\n",
    "### 1. Set up connection to IBM Db2 Event Store\n",
    "\n",
    "**In this demo, we assume your IBM Db2 Event Store is installed with Watson Studio Local (WSL).**\n",
    "\n",
    "You will need to set the Watson Studio Local's `userID` and `password` that will be used to connect to IBM Db2 Event Store instance.\n",
    "\n",
    "By default, the connection will be estabilished to the IBM Db2 Event Store instance on the current Watson Studio Local cluster.\n",
    "\n",
    "For more details on setting up IBM Db2 Event Store connection in Jupyter Notebook, please read the official documentation:\n",
    "https://www.ibm.com/support/knowledgecenter/en/SSGNPV_2.0.0/dsx/jupyter_prereq.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using the configuration reader API, set up the userID and password that \n",
    "# will be used to connect to IBM Db2 Event Store.\n",
    "\n",
    "ConfigurationReader.setEventUser(\"admin\")\n",
    "ConfigurationReader.setEventPassword(\"password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Connect to the database\n",
    "**IBM Event Store 2.0 instance will by default have a database created with name `EVENTDB`, and the default database `EVENTDB` should not be deleted. Each IBM Event Store 2.0 instance only support exact ONE database.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dbName = \"EVENTDB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To run Spark SQL queries, you must set up a Db2 Event Store Spark session. SparkSession is the entry point to programming Spark with the Dataset and DataFrame API. The EventSession class extends the optimizer of the SparkSession class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"EventStore SQL in Python\").getOrCreate()\n",
    "eventSession = EventSession(sparkSession.sparkContext, dbName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now you can execute the command to connect to the database in the event session you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eventSession.open_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Exploring the database by retrieving all tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The following code section retrieves the names of all tables that exist in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event context successfully retrieved.\n",
      "ADMIN.DHT_TABLE\n",
      "ADMIN.SDS_TABLE\n"
     ]
    }
   ],
   "source": [
    "with EventContext.get_event_context(dbName) as ctx:\n",
    "   print(\"Event context successfully retrieved.\")\n",
    "\n",
    "table_names = ctx.get_names_of_tables()\n",
    "for idx, name in enumerate(table_names):\n",
    "   print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Creating a table with an index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Like you saw above, there are no tables in the database, we are going to come back to those cells after we create a table to see the table was created. The next cell defined the table name we want to create:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tabName = \"IOT_TEMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from eventstore.catalog import TableSchema\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "tabSchema = TableSchema(tabName, StructType([\n",
    "    StructField(\"deviceID\", IntegerType(), nullable = False),\n",
    "    StructField(\"sensorID\", IntegerType(), nullable = False),\n",
    "    StructField(\"ts\", LongType(), nullable = False),\n",
    "    StructField(\"ambient_temp\", DoubleType(), nullable = False),\n",
    "    StructField(\"power\", DoubleType(), nullable = False),\n",
    "    StructField(\"temperature\", DoubleType(), nullable = False)\n",
    "    ]),\n",
    "    sharding_columns = [\"deviceID\", \"sensorID\"],\n",
    "    pk_columns = [\"deviceID\", \"sensorID\", \"ts\"]\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And the following cell defines the index schema that includes two equality columns (deviceID and sensorId), the entries are sorted in timestamp descending order, and includes the `reading` column to speed up queries that retrieve readings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from eventstore.catalog import IndexSpecification, SortSpecification, ColumnOrder\n",
    "\n",
    "indexSchema = IndexSpecification(\n",
    "          index_name=tabName + \"Index\",\n",
    "          table_schema=tabSchema,\n",
    "          equal_columns = [\"deviceID\", \"sensorID\"],\n",
    "          sort_columns = [\n",
    "            SortSpecification(\"ts\", ColumnOrder.DESCENDING_NULLS_LAST)],\n",
    "          include_columns = [\"temperature\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally, the following cell is used to create the table with the index using the create_table_with_index method, passing both the table schema and index schema defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(dbName) as ctx:\n",
    "   res = ctx.create_table_with_index(tabSchema,indexSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To drop a table we use the drop_table command, like in the cell below, but it is commented out and provided here only as a reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# with EventContext.get_event_context(\"EVENTDB\") as ctx:\n",
    "#     ctx.drop_table(tabName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. Loading the tables and inspecting the table schemas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To manipulate or retrieve data from tables you need to load the corresponding tables and get the data frame references to be able to access the tables with your queries. The following code loads all tables and creates a temp view for each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tables: \n",
      "\t0: ADMIN.DHT_TABLE\n",
      "\t1: ADMIN.IOT_TEMP\n",
      "\t2: ADMIN.SDS_TABLE\n"
     ]
    }
   ],
   "source": [
    "with EventContext.get_event_context(dbName) as ctx:\n",
    "    print(\"tables: \")\n",
    "    table_names = ctx.get_names_of_tables()\n",
    "    for idx, name in enumerate(table_names):\n",
    "        print(\"\\t{}: {}\".format(idx, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then the following cell can be used to show the schema of the table created. \n",
    "\n",
    "** In the IBM Db2 Event Store 2.0, the following objects have case insensitive names by default: schema, column and index.**  \n",
    "All the user provided names for the above objects are converted to upper cases in the catalog. Users can explicitly enable the case sensitivity by wrapping the object names with single quotes, for example, ` '<Name>' `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResolvedTableSchema(tableName=ADMINIOT_TEMP, schema=StructType(List(StructField(DEVICEID,IntegerType,false),StructField(SENSORID,IntegerType,false),StructField(TS,LongType,false),StructField(AMBIENT_TEMP,DoubleType,false),StructField(POWER,DoubleType,false),StructField(TEMPERATURE,DoubleType,false))), sharding_columns=[u'DEVICEID', u'SENSORID'], pk_columns=[u'DEVICEID', u'SENSORID', u'TS'], partition_columns=None, schema_name=Some(ADMIN))\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    resolved_table_schema = ctx.get_table(tabName)\n",
    "    print(resolved_table_schema)\n",
    "except Exception as err:\n",
    "    print(\"Table not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary\n",
    "In this notebook, you learned:\n",
    "- how to connect to a local and remote IBM Db2 Event Store\n",
    "- how to open a database\n",
    "- how to define a table schema and index schema\n",
    "- how to create a database table with an index\n",
    "- how to list the tables in a database and their schemas\n",
    "\n",
    "### Next Step: Load data into the table\n",
    "With the newly created database and table, you will need to insert some data into the table before starting analysis.\n",
    "To load data into the table, you will have to:\n",
    "- Copy the `NFS_setup.sh` and `./load.sh` scripts located under `db2eventstore-IoT-Analytics/data/` in this repo to the installation node on your cluster.\n",
    "- Run the `NFS_setup.sh` script to setup NFS server that will be used as external table source for your Event Store instance.  \n",
    "  The script will also download the sample csv data file located at `db2eventstore-IoT-Analytics/data/sample_IOT_table.csv` to the NFS server.  \n",
    "  Example: `./NFS_setup.sh --namespace dsx`\n",
    "- Run \"load.sh\" to load sample data to the `ADMIN.IOT_TEMP` table.  \n",
    "  Example: `./load.sh --namespace dsx`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7 with Watson Studio Spark 2.0.2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
