{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Pre-requisite:\n",
    "Before running this notebook, you will have to:\n",
    "1. download the csv file named `dht_1k.csv` and `sds_1k.csv`  \n",
    "stored under https://github.com/IBMProjectEventStore/db2eventstore-IoT-Analytics/tree/master/data.\n",
    "2. Go to the `Project tab` and load both above mentioned csv files into the current project as dataset.\n",
    "----\n",
    "**Note: This Notebook can only run in Python version >= 3.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from eventstore.oltp import EventContext\n",
    "from eventstore.sql import EventSession\n",
    "from eventstore.common import ConfigurationReader\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "ConfigurationReader.setEventUser(\"user5\")\n",
    "ConfigurationReader.setEventPassword(\"EventStore20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"EventStore SQL in Python\").getOrCreate()\n",
    "eventSession = EventSession(sparkSession.sparkContext, \"EVENTDB\")\n",
    "eventSession.set_query_read_option(\"SnapshotNow\")\n",
    "eventSession._jvm.org.apache.spark.sql.types.SqlTimeSeries.register(eventSession._jsparkSession)\n",
    "eventSession.open_database()\n",
    "ctx = EventContext.get_event_context(\"EVENTDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from eventstore.catalog import TableSchema\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 USER5.DHT_FULL_TABLE\n",
      "1 USER5.IOT_TEMP_NOTEBOOK_SAMPLE\n"
     ]
    }
   ],
   "source": [
    "table_names = ctx.get_names_of_tables()\n",
    "for idx, name in enumerate(table_names):\n",
    "    print(idx, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def datetime_converter(datetime_string):\n",
    "    # (1) Convert to datetime format\n",
    "    utc_time = datetime.strptime(datetime_string.split('.000Z')[0], \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "    return int((utc_time - datetime(1970, 1, 1)).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## create table and loading data for DHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Define table schema to be created\n",
    "with EventContext.get_event_context(\"EVENTDB\") as ctx:\n",
    "    schema = StructType([\n",
    "        StructField(\"sensor_id\", IntegerType(), nullable = False),\n",
    "        StructField(\"timestamp\", IntegerType(), nullable = False),\n",
    "        StructField(\"location\", IntegerType(), nullable = False),\n",
    "        StructField(\"humidity\", FloatType(), nullable = True)\n",
    "    ])  \n",
    "    table_schema = TableSchema(\"dht_table\", schema,\n",
    "                                sharding_columns=[\"sensor_id\"],\n",
    "                                pk_columns=[\"sensor_id\",\"timestamp\",\"location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER5.DHT_FULL_TABLE\n",
      "USER5.IOT_TEMP_NOTEBOOK_SAMPLE\n",
      "USER5.DHT_TABLE\n"
     ]
    }
   ],
   "source": [
    "# try create table if not exist\n",
    "# try:\n",
    "#     ctx.drop_table(\"DHT_TABLE\")\n",
    "# except Exception as error:\n",
    "#     print(error)\n",
    "try:\n",
    "    ctx.create_table(table_schema)\n",
    "except Exception as error:\n",
    "    pass\n",
    "    \n",
    "table_names = ctx.get_names_of_tables()\n",
    "for idx, name in enumerate(table_names):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dht_table = eventSession.load_event_table(\"dht_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResolvedTableSchema(tableName=USER5DHT_TABLE, schema=StructType(List(StructField(SENSOR_ID,IntegerType,false),StructField(TIMESTAMP,IntegerType,false),StructField(LOCATION,IntegerType,false),StructField(HUMIDITY,FloatType,true))), sharding_columns=['SENSOR_ID'], pk_columns=['SENSOR_ID', 'TIMESTAMP', 'LOCATION'], partition_columns=None, schema_name=Some(USER5))\n"
     ]
    }
   ],
   "source": [
    "# ingest data into table\n",
    "import os\n",
    "resolved_table_schema = ctx.get_table(\"dht_table\")\n",
    "print(resolved_table_schema)\n",
    "with open(os.environ['DSX_PROJECT_DIR']+'/datasets/dht_1k.csv') as f:\n",
    "    f.readline()\n",
    "    content = f.readlines()\n",
    "content = [l.split(\",\") for l in content]\n",
    "batch = [dict(sensor_id=int(c[5]), timestamp=datetime_converter(c[7]), location=int(c[0]), humidity=float(c[2])) for c in content]\n",
    "ctx.batch_insert(resolved_table_schema, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# verify ingested result\n",
    "dht_table = eventSession.load_event_table(\"dht_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dht_table.createOrReplaceTempView(\"dht_raw_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   41569|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eventSession.sql(\"select count(*) from dht_raw_table\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## create table and loading data for SDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(\"EVENTDB\") as ctx:\n",
    "    schema = StructType([\n",
    "        StructField(\"sensor_id\", IntegerType(), nullable = False),\n",
    "        StructField(\"timestamp\", LongType(), nullable = False),\n",
    "        StructField(\"location\", IntegerType(), nullable = False),\n",
    "        StructField(\"p_1\", DoubleType(), nullable = True)\n",
    "    ])  \n",
    "    table_schema = TableSchema(\"sds_table\", schema,\n",
    "                                sharding_columns=[\"sensor_id\"],\n",
    "                                pk_columns=[\"sensor_id\",\"timestamp\",\"location\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER5.DHT_FULL_TABLE\n",
      "USER5.IOT_TEMP_NOTEBOOK_SAMPLE\n",
      "USER5.DHT_TABLE\n",
      "USER5.SDS_TABLE\n"
     ]
    }
   ],
   "source": [
    "# try:\n",
    "#     ctx.drop_table(\"SDS_TABLE\")\n",
    "# except Exception as error:\n",
    "#     print(error)\n",
    "try:\n",
    "    ctx.create_table(table_schema)\n",
    "except Exception as error:\n",
    "    print(\"Table not created.\")\n",
    "table_names = ctx.get_names_of_tables()\n",
    "for idx, name in enumerate(table_names):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sds_table = eventSession.load_event_table(\"sds_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(\"EVENTDB\") as ctx:\n",
    "    resolved_table_schema = ctx.get_table(\"sds_table\")\n",
    "    with open(os.environ['DSX_PROJECT_DIR']+'/datasets/sds_1k.csv') as f:\n",
    "        f.readline()\n",
    "        content = f.readlines()\n",
    "    content = [l.split(\",\") for l in content]\n",
    "    batch = [dict(sensor_id=int(c[5]), timestamp=datetime_converter(c[7]), location=int(c[0]), p_1=float(c[2])) for c in content if c[2] != \"\"]\n",
    "    ctx.batch_insert(resolved_table_schema, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51247"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sds_table=eventSession.load_event_table(\"sds_table\")\n",
    "sds_table.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sds_table.createOrReplaceTempView(\"sds_raw_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+-----+\n",
      "|SENSOR_ID| TIMESTAMP|LOCATION|  P_1|\n",
      "+---------+----------+--------+-----+\n",
      "|     5323|1504051345|    2684| 29.0|\n",
      "|     5323|1504051492|    2684| 27.5|\n",
      "|     5323|1504051638|    2684|27.43|\n",
      "|     5323|1504051785|    2684| 30.1|\n",
      "|     5323|1504051931|    2684|28.73|\n",
      "+---------+----------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eventSession.sql(\"select * from sds_raw_table\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   41569|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql=\"SELECT count(*) FROM dht_raw_table\"\n",
    "eventSession.sql(sql).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Alignment of multiple time-series from different IoT sensors\n",
    "\n",
    "The below example shows how one can align two timeseries using an inner join with the nearest timestamp. The problem arises when two sensors are generating timestamps with clocks that are not fully synchronized. This can occur regularly and is common in IoT scenarios.\n",
    "\n",
    "In what follows, we will show an example on the OK Lab data that considers the timeseries generated by the SDS (particulate matter) sensors and the DHT (humidity/temperature) sensors. The manual of SDS states that the SDS values are valid only when the DHT sensor measures humidity as < 70%. Realizing this restraint requires the data from the 2 sensors to be synchronized temporally. We note first that traditional join style would be to look for exact timestamps, which will not work in this case as the sensors are coming from two different devices (with the same location). One approach would be to use a standard SQL statement such as:\n",
    "\n",
    "```sql\n",
    "SELECT \n",
    "    humidity, \n",
    "    p_1\n",
    "FROM sds_raw_table STORED AS PARQUET sds011, dht_raw_table STORED AS PARQUET dht22\n",
    "AND dht22.humidity <= 70\n",
    "AND ((sds011.timestamp - INTERVAL 10 SECONDS) < dht22.timestamp) \n",
    "AND (dht22.timestamp < (sds011.timestamp + INTERVAL 10 SECONDS))\n",
    "```\n",
    "\n",
    "However, if executed as it stands, it can take several hours to complete given that it results in a traditional Cartesian Join.\n",
    "\n",
    "In our example, we will down-select the data using DB2 Eventstore into two dataframes (sds and dht). Our approach then is to do a clever join that takes windowing into account and not do a full Cartesian join. \n",
    "\n",
    "In what follows, we we will show how using time-series capabilities of DB2-Eventstore can be used to address this problem of unaligned sensors. Although this is one application that time-series for DB2-eventstore covers, time-series capabilites are not limited to just this one use case as we have functions to handle simple statistical methods (fft, avg, percentile, etc.), time-series distance metrics (DL, DTW, SBD, etc.), sophisticated forms of segmentation (time-based, anchor-base, marker-base, record-based, etc.), etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Initial exploration on data\n",
    "\n",
    "In many cases, the first step to doing any Time-Series analysis is to learn about your time-series. To do so, we use what is called a describe. This will provide a rich set of metrics (avg, percentiles, timing-statistics, etc.) over a time-series such that a user can have some knowledge of the time-series they are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>ts_time_min</th>\n",
       "      <th>ts_time_max</th>\n",
       "      <th>ts_time_mean</th>\n",
       "      <th>ts_mode</th>\n",
       "      <th>ts_unique</th>\n",
       "      <th>ts_frequency</th>\n",
       "      <th>ts_first_time_tick</th>\n",
       "      <th>ts_first_value</th>\n",
       "      <th>ts_last_time_tick</th>\n",
       "      <th>ts_last_value</th>\n",
       "      <th>ts_count</th>\n",
       "      <th>ts_num_mean</th>\n",
       "      <th>ts_num_std</th>\n",
       "      <th>ts_num_min</th>\n",
       "      <th>ts_num_max</th>\n",
       "      <th>ts_num_25</th>\n",
       "      <th>ts_num_50</th>\n",
       "      <th>ts_num_75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2662</td>\n",
       "      <td>146</td>\n",
       "      <td>50321</td>\n",
       "      <td>277.408397</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>387</td>\n",
       "      <td>12</td>\n",
       "      <td>1503834699</td>\n",
       "      <td>37.900002</td>\n",
       "      <td>1504198104</td>\n",
       "      <td>50.700001</td>\n",
       "      <td>1311</td>\n",
       "      <td>46.191533</td>\n",
       "      <td>12.138422</td>\n",
       "      <td>27.299999</td>\n",
       "      <td>69.900002</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>43.500000</td>\n",
       "      <td>57.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2683</td>\n",
       "      <td>146</td>\n",
       "      <td>46404</td>\n",
       "      <td>317.732601</td>\n",
       "      <td>57.799999</td>\n",
       "      <td>159</td>\n",
       "      <td>6</td>\n",
       "      <td>1504034813</td>\n",
       "      <td>69.400002</td>\n",
       "      <td>1504121554</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>274</td>\n",
       "      <td>56.771533</td>\n",
       "      <td>6.525704</td>\n",
       "      <td>42.200001</td>\n",
       "      <td>69.900002</td>\n",
       "      <td>51.200001</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>60.400002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2682</td>\n",
       "      <td>146</td>\n",
       "      <td>36449</td>\n",
       "      <td>274.428233</td>\n",
       "      <td>44.299999</td>\n",
       "      <td>275</td>\n",
       "      <td>13</td>\n",
       "      <td>1503960327</td>\n",
       "      <td>67.699997</td>\n",
       "      <td>1504191670</td>\n",
       "      <td>69.800003</td>\n",
       "      <td>844</td>\n",
       "      <td>51.431398</td>\n",
       "      <td>9.830193</td>\n",
       "      <td>33.400002</td>\n",
       "      <td>69.900002</td>\n",
       "      <td>43.900002</td>\n",
       "      <td>48.099998</td>\n",
       "      <td>61.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2680</td>\n",
       "      <td>147</td>\n",
       "      <td>40779</td>\n",
       "      <td>241.413181</td>\n",
       "      <td>25.200001</td>\n",
       "      <td>370</td>\n",
       "      <td>9</td>\n",
       "      <td>1503990245</td>\n",
       "      <td>69.400002</td>\n",
       "      <td>1504180720</td>\n",
       "      <td>69.199997</td>\n",
       "      <td>790</td>\n",
       "      <td>45.783544</td>\n",
       "      <td>14.517849</td>\n",
       "      <td>21.799999</td>\n",
       "      <td>69.900002</td>\n",
       "      <td>31.150001</td>\n",
       "      <td>45.800001</td>\n",
       "      <td>58.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2684</td>\n",
       "      <td>133</td>\n",
       "      <td>38120</td>\n",
       "      <td>241.702523</td>\n",
       "      <td>67.199997</td>\n",
       "      <td>350</td>\n",
       "      <td>8</td>\n",
       "      <td>1503994577</td>\n",
       "      <td>69.699997</td>\n",
       "      <td>1504176579</td>\n",
       "      <td>69.800003</td>\n",
       "      <td>754</td>\n",
       "      <td>49.919231</td>\n",
       "      <td>13.417248</td>\n",
       "      <td>23.900000</td>\n",
       "      <td>69.800003</td>\n",
       "      <td>38.299999</td>\n",
       "      <td>52.400000</td>\n",
       "      <td>61.799999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   location  ts_time_min  ts_time_max  ts_time_mean    ts_mode  ts_unique  \\\n",
       "0      2662          146        50321    277.408397  30.000000        387   \n",
       "1      2683          146        46404    317.732601  57.799999        159   \n",
       "2      2682          146        36449    274.428233  44.299999        275   \n",
       "3      2680          147        40779    241.413181  25.200001        370   \n",
       "4      2684          133        38120    241.702523  67.199997        350   \n",
       "\n",
       "   ts_frequency  ts_first_time_tick  ts_first_value  ts_last_time_tick  \\\n",
       "0            12          1503834699       37.900002         1504198104   \n",
       "1             6          1504034813       69.400002         1504121554   \n",
       "2            13          1503960327       67.699997         1504191670   \n",
       "3             9          1503990245       69.400002         1504180720   \n",
       "4             8          1503994577       69.699997         1504176579   \n",
       "\n",
       "   ts_last_value  ts_count  ts_num_mean  ts_num_std  ts_num_min  ts_num_max  \\\n",
       "0      50.700001      1311    46.191533   12.138422   27.299999   69.900002   \n",
       "1      69.000000       274    56.771533    6.525704   42.200001   69.900002   \n",
       "2      69.800003       844    51.431398    9.830193   33.400002   69.900002   \n",
       "3      69.199997       790    45.783544   14.517849   21.799999   69.900002   \n",
       "4      69.800003       754    49.919231   13.417248   23.900000   69.800003   \n",
       "\n",
       "   ts_num_25  ts_num_50  ts_num_75  \n",
       "0  35.400002  43.500000  57.799999  \n",
       "1  51.200001  57.750000  60.400002  \n",
       "2  43.900002  48.099998  61.500000  \n",
       "3  31.150001  45.800001  58.500000  \n",
       "4  38.299999  52.400000  61.799999  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stmt = \"\"\"SELECT location, TS_DESCRIBE(ts) FROM ( SELECT location,TIME_SERIES(timestamp, humidity) AS ts FROM dht_raw_table where humidity < 70 GROUP BY location)\n",
    "\"\"\"\n",
    "\n",
    "df = eventSession.sql(stmt).toPandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Description of performing a time-series sql temporal align\n",
    "\n",
    "This query has a few main things to consider:\n",
    "\n",
    "### Creating your time series\n",
    "\n",
    "first a time series must be created\n",
    "\n",
    "#### sds time series\n",
    "\n",
    "```sql\n",
    "SELECT location, D_TIME_SERIES(timestamp, p_1) AS sds FROM sds_raw_table GROUP BY location\n",
    "```\n",
    "\n",
    "#### dht time series\n",
    "\n",
    "```sql\n",
    "SELECT location, D_TIME_SERIES(timestamp, humidity) AS dht FROM dht_raw_table GROUP BY location\n",
    "```\n",
    "\n",
    "### Performing full temporal align\n",
    "\n",
    "Performing a full temporal align requires 2 parameters:\n",
    "\n",
    "- The left Time Series\n",
    "- The right Time Series\n",
    "\n",
    "Once given, the returned output will be 2 columns (the 2 aligned time series) as **left_column_aligned** and **right_column_aligned**\n",
    "\n",
    "*Note: With this method, all missing values will be replaced with null*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|location|         dht_aligned|         sds_aligned|\n",
      "+--------+--------------------+--------------------+\n",
      "|    2662|[(1503834699,37.9...|[(1503834699,5.33...|\n",
      "|    2683|[(1503961757,-1.0...|[(1503961757,4.8)...|\n",
      "|    2682|[(1503960326,-1.0...|[(1503960326,8.87...|\n",
      "|    2680|[(1503958922,-1.0...|[(1503958922,30.8...|\n",
      "|    2684|[(1503963045,-1.0...|[(1503963045,38.3...|\n",
      "|    1773|[(1501703936,-1.0...|[(1501703936,424....|\n",
      "|    2633|[(1503575337,-1.0...|[(1503575337,6.2)...|\n",
      "|    1323|[(1503897678,-1.0...|[(1503897678,6.27...|\n",
      "|    2686|[(1503964139,64.4...|[(1503964139,7.0)...|\n",
      "|    2681|[(1503960072,-1.0...|[(1503960072,24.2...|\n",
      "|     966|[(1501545689,-1.0...|[(1501545689,7.83...|\n",
      "|    2640|[(1503609572,64.4...|[(1503609572,3.0)...|\n",
      "|     732|[(1501545688,-1.0...|[(1501545688,0.3)...|\n",
      "|    2652|[(1503702364,67.9...|[(1503702364,9.1)...|\n",
      "|    1314|[(1501577454,53.5...|[(1501577454,5.43...|\n",
      "|     462|[(1501545650,-1.0...|[(1501545650,4.6)...|\n",
      "|    1216|[(1503964855,-1.0...|[(1503964855,6.57...|\n",
      "|     314|[(1504029923,63.2...|[(1504029923,11.1...|\n",
      "|    1099|[(1503932184,-1.0...|[(1503932184,7.03...|\n",
      "|    2408|[(1501905944,-1.0...|[(1501905944,2.1)...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stmt = \"\"\"\n",
    "    SELECT sds_table.location, TS_FULL_ALIGN(dht, sds, TS_INTERPOLATOR_NEAREST(-1.0)) FROM \n",
    "        (SELECT location, TIME_SERIES(timestamp, humidity) AS dht FROM dht_raw_table where humidity < 70 GROUP BY location) AS dht_table\n",
    "        INNER JOIN\n",
    "        (SELECT location, TIME_SERIES(timestamp, p_1) AS sds FROM sds_raw_table GROUP BY location) AS sds_table\n",
    "        ON dht_table.location = sds_table.location\n",
    "\"\"\"\n",
    "df = eventSession.sql(stmt)\n",
    "df.show()\n",
    "df.count()\n",
    "eventSession.sql(stmt).createOrReplaceTempView(\"dht_sds_ts_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Display the aligned TimeSeries table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|      23|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eventSession.sql(\"select count(*) from dht_sds_ts_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Interpolate missing values after alignment\n",
    "\n",
    "Because in IoT use cases, sensors tend to be clocked at different rates, it's important to properly fill values where they don't exist in the data. Just because a value is not in our data, does not mean it did not exist. To approximate the missing value, we can provide an interpolator as simple as nearest, next, prev, but as sophisticated as linear interpolation or cubic spline interpolation. In the following example, we will fill all missing values based on a nearest interpolation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eventSession.sql(\"SELECT location, TS_FILLNA(dht_aligned,TS_INTERPOLATOR_NEAREST(-1.0)) as ts FROM dht_sds_ts_table\").createOrReplaceTempView(\"dht_no_nulls\")\n",
    "eventSession.sql(\"SELECT location, TS_FILLNA(sds_aligned,TS_INTERPOLATOR_NEAREST(-1.0)) as ts FROM dht_sds_ts_table\").createOrReplaceTempView(\"sds_no_nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Converting Time-Series data to tabular data\n",
    "\n",
    "Once all Time-Series analysis has been done, because Time-Series types are not directly ingestable, a user may want to display there data in a tabular format to prepare for graphing or performing further analysis. The following is how would could convert that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eventSession.sql(\"SELECT location, TS_EXPLODE(ts) FROM dht_no_nulls\").createOrReplaceTempView(\"dht_exploded\")\n",
    "eventSession.sql(\"SELECT location, TS_EXPLODE(ts) FROM sds_no_nulls\").createOrReplaceTempView(\"sds_exploded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42953"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventSession.sql(\"select * from dht_exploded\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42953"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventSession.sql(\"select * from sds_exploded\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Joining the tabular data\n",
    "\n",
    "Lastly, we will perform a classical join on the location and time_tick for humidity and coarse particulate matter data to properly display the aligned values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+------------------+-----+\n",
      "|location| timestamp|          humidity|  p_1|\n",
      "+--------+----------+------------------+-----+\n",
      "|     138|1501548094|               1.0|  5.9|\n",
      "|     138|1501564534|               1.0|  7.2|\n",
      "|     138|1501583914|               1.0|  4.1|\n",
      "|     138|1501604784|               1.0|  4.2|\n",
      "|     138|1501606399|               1.0| 4.83|\n",
      "|     138|1501610653|               1.0| 8.07|\n",
      "|     138|1501636474|58.400001525878906| 5.63|\n",
      "|     138|1501656427|               1.0|  4.1|\n",
      "|     138|1501683577|               1.0|  7.9|\n",
      "|     314|1504069209|56.400001525878906| 9.52|\n",
      "|     314|1504105745| 53.20000076293945|  4.8|\n",
      "|     314|1504109853|54.599998474121094| 5.05|\n",
      "|     314|1504115575|58.099998474121094|10.38|\n",
      "|     314|1504127465| 62.70000076293945|  8.5|\n",
      "|     314|1504165064|  69.9000015258789| 3.95|\n",
      "|     314|1504184729| 63.29999923706055| 1.58|\n",
      "|     314|1504218776|  69.9000015258789| 3.08|\n",
      "|     462|1501580732| 65.19999694824219|  5.6|\n",
      "|     462|1501593053|55.400001525878906|  4.4|\n",
      "|     462|1501624743| 69.30000305175781|  7.1|\n",
      "+--------+----------+------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42953"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stmt = \"\"\"\n",
    "    select dht_exploded.location, dht_exploded.ts_timeTick as timestamp, dht_exploded.ts_value as humidity, sds_exploded.ts_value as p_1 FROM\n",
    "        dht_exploded\n",
    "        INNER JOIN\n",
    "        sds_exploded\n",
    "        ON dht_exploded.location=sds_exploded.location and dht_exploded.ts_timeTick=sds_exploded.ts_timeTick\n",
    "\"\"\"\n",
    "df = eventSession.sql(stmt)\n",
    "df.show()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Timing for Time-Series SQL\n",
    "This section shows how long it takes to run each time-series SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 dht|\n",
      "+--------------------+\n",
      "|[(1501545650,87.1...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "stmt = \"SELECT TIME_SERIES(timestamp, humidity) AS dht FROM dht_raw_table\"\n",
    "\n",
    "df = eventSession.sql(stmt)\n",
    "df.cache()\n",
    "df.createOrReplaceTempView(\"table_a\")\n",
    "start = time.time()\n",
    "df.show()\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingestion time: 125.03376197814941 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = end - start\n",
    "print(\"ingestion time: \" + str(total_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          dht_interp|\n",
      "+--------------------+\n",
      "|[(1501545600,0.0)...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stmt = \"SELECT TS_RESAMPLE(dht, 3600, TS_INTERPOLATOR_NEAREST(0.0)) as dht_interp from table_a\"\n",
    "start = time.time()\n",
    "eventSession.sql(stmt).show()\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingestion time: 0.43882179260253906 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = end - start\n",
    "print(\"ingestion time: \" + str(total_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   41569|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stmt = \"select count(*) from (SELECT TS_EXPLODE(dht) from table_a)\"\n",
    "start = time.time()\n",
    "eventSession.sql(stmt).show()\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingestion time: 0.1370067596435547 seconds\n"
     ]
    }
   ],
   "source": [
    "total_time = end - start\n",
    "print(\"ingestion time: \" + str(total_time) + \" seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7",
   "language": "python",
   "name": "py2localspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
