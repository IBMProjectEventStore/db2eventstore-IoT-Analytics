{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# IBM Db2 Event Store - Data Analytics using Python API \n",
    "\n",
    "IBM Db2 Event Store is a hybrid transactional/analytical processing (HTAP) system that is designed for IoT workloads. It is empowered by the Db2 Common SQL Engine, the most sophisticated SQL-based analytics query engine available. IBM Db2 Event Store can handle complex queries quickly and efficiently. IBM Db2 Event Store also provides rich data science tooling which allow the arriving data to be quickly and eaily analyzed.\n",
    "\n",
    "> This Demo is created with IBM Db2 Event Store 2.0 Enterprise edition.\n",
    "\n",
    "This notebook illustrates how the IBM Db2 Event Store can be integrated with multiple popular scientific tools to perform data analytics.\n",
    "\n",
    "***Pre-Req: Event_Store_Querying_on_Table***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import event store's Python client interface libraries\n",
    "%matplotlib inline  \n",
    "from eventstore.common import ConfigurationReader\n",
    "from eventstore.oltp import EventContext\n",
    "from eventstore.sql import EventSession\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"connect-to-es\"></a>\n",
    "### 1. Set up connection to IBM Db2 Event Store\n",
    "\n",
    "**In this demo, we assume your IBM Db2 Event Store is installed with Watson Studio Local (WSL).**\n",
    "\n",
    "You will need to set the Watson Studio Local's `userID` and `password` that will be used to connect to IBM Db2 Event Store instance.\n",
    "\n",
    "By default, the connection will be estabilished to the IBM Db2 Event Store instance on the current Watson Studio Local cluster.\n",
    "\n",
    "For more details on setting up IBM Db2 Event Store connection in Jupyter Notebook, please read the official documentation:\n",
    "https://www.ibm.com/support/knowledgecenter/en/SSGNPV_2.0.0/dsx/jupyter_prereq.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setting the IP address to connect to your IBM Db2 Event Store cluster\n",
    "\n",
    "For this, you will need to find out the connection string to your IBM Db2 Event Store cluster.\n",
    "\n",
    "Perform the following steps:\n",
    "\n",
    "- Replace the IP address in the below program code with the IP address of your local host\n",
    "- Then execute the program cell below. It will connect to the IBM Db2 Event Store cluster in the provided connection string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using the configuration reader API, set up the userID and password that \n",
    "# will be used to connect to IBM Db2 Event Store.\n",
    "\n",
    "ConfigurationReader.setEventUser(\"admin\")\n",
    "ConfigurationReader.setEventPassword(\"password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Connect to the database\n",
    "**IBM Event Store 2.0 instance will by default have a database created with name `EVENTDB`, and the default database `EVENTDB` should not be deleted. Each IBM Event Store 2.0 instance only support exact ONE database.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dbName = \"EVENTDB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To run Spark SQL queries, you must set up a Db2 Event Store Spark session. SparkSession is the entry point to programming Spark with the Dataset and DataFrame API. The EventSession class extends the optimizer of the SparkSession class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"EventStore SQL in Python\").getOrCreate()\n",
    "eventSession = EventSession(sparkSession.sparkContext, dbName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now you can execute the command to open the database in the event session you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eventSession.open_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Exploring the database by retrieving all tables\n",
    "The following code section retrieves the names of all tables that exist in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(dbName) as ctx:\n",
    "   print(\"Event context successfully retrieved.\")\n",
    "\n",
    "table_names = ctx.get_names_of_tables()\n",
    "for idx, name in enumerate(table_names):\n",
    "   print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we have the name of the existing table. We then load the corresponding table and get the data frame references to access the table with query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tabName = \"IOT_TEMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tab = eventSession.load_event_table(tabName)\n",
    "print(\"Table \"+tabName+\" successfully loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's recall the table schema we previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    resolved_table_schema = ctx.get_table(tabName)\n",
    "    print(resolved_table_schema)\n",
    "except Exception as err:\n",
    "    print(\"Table not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And in the following cell we create a temp view with that data frame called `readings` hat we will use in the queries below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Data Analytics with IBM Db2 Event Store\n",
    "Data analytics tasks can be performed on table stored in the IBM Db2 Event Store database with various data analytic tools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's first take a look at the timestamp range of the record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tab.createOrReplaceTempView(\"readings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT MIN(ts) MIN_TS, MAX(ts) MAX_TS FROM readings\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "df_data = eventSession.sql(query)\n",
    "df_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The following cell converts the timestamps in miliseconds to datetime to make it human readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "MIN_TS=1541019342393\n",
    "MAX_TS=1541773999825\n",
    "print(\"The time range of the dataset is from {} to {}\".format(datetime.datetime.fromtimestamp(MIN_TS/1000).strftime('%Y-%m-%d %H:%M:%S'), \n",
    "                                                               datetime.datetime.fromtimestamp(MAX_TS/1000).strftime('%Y-%m-%d %H:%M:%S')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Sample Problem\n",
    "Assume we are only interested in the data recorded by the 12th sensor on the 1st device in the time period on the day of 2018-11-01. And we want to investigate the effects of power consumption and ambient power on the temperature recorded by the sensor in this date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Because the timestamp is recorded in milisec, we need to convert the datetime of interest to a time range in milisec. And then use the range as a filter in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "start_ts = (datetime.datetime(2018,11,1,0,0) - datetime.datetime(1970,1,1)).total_seconds() * 1000\n",
    "end_ts = (datetime.datetime(2018,11,2,0,0) - datetime.datetime(1970,1,1)).total_seconds() * 1000\n",
    "print(\"The time range of datetime 2018-11-01 in milisec is from {:.0f} to {:.0f}\".format(start_ts, end_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "IBM Db2 Event Store extends the Spark SQL interface, which allows users to apply filters with SQL queries at ease.  \n",
    "\n",
    "In the following cell, the relevant data are extracted according to the problem scope. Note that because we are specifying a specific device and sensor, this query is fully exploiting the index defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM readings WHERE deviceID=1 AND sensorID=12 AND ts >1541030400000 AND ts < 1541116800000 ORDER BY ts\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "refined_data = eventSession.sql(query)\n",
    "refined_data.createOrReplaceTempView(\"refined_reading\")\n",
    "refined_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Basic Statistics \n",
    "For numerical data, knowing the descriptive summary statistics can help a lot in understanding the distribution of the data.  \n",
    "\n",
    "IBM Event Store extends the Spark DataFrame functionality. We can use the `describe` function to retrieve multiple statistics of table stored in IBM Event Store database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "refined_data.describe().toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It's worth noticing that some power reading records are negative, which may be caused by sensor error. The records with negative power reading will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM readings WHERE deviceID=1 AND sensorID=12 AND ts >1541030400000 AND ts < 1541116800000 AND power > 0 ORDER BY ts\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "refined_data = eventSession.sql(query)\n",
    "refined_data.createOrReplaceTempView(\"refined_reading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Total number of records in the refined table view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT count(*) count FROM refined_reading\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "df_data = eventSession.sql(query)\n",
    "df_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Covariance and correlation\n",
    "- Covariance is a measure of how two variables change with respect to each other. It can be examined by calling `.stat.cov()` function on the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "refined_data.stat.cov(\"AMBIENT_TEMP\",\"TEMPERATURE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "refined_data.stat.cov(\"POWER\",\"TEMPERATURE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Correlation is a normalized measure of covariance that is easier to understand, as it provides quantitative measurements of the statistical dependence between two random variables.  It can be examined by calling `.stat.corr()` function on the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "refined_data.stat.corr(\"AMBIENT_TEMP\",\"TEMPERATURE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "refined_data.stat.corr(\"POWER\",\"TEMPERATURE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualization\n",
    "Visualization of each feature provides insights of the underlying distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Distribution of Ambient Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT ambient_temp FROM refined_reading\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "ambient_temp = eventSession.sql(query)\n",
    "ambient_temp= ambient_temp.toPandas()\n",
    "ambient_temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(16,6))\n",
    "stats.probplot(ambient_temp.iloc[:,0], plot=plt.subplot(1,3,1))\n",
    "axs[1].boxplot(ambient_temp.iloc[:,0])\n",
    "axs[1].set_title(\"Boxplot on Ambient_temp\")\n",
    "axs[2].hist(ambient_temp.iloc[:,0], bins = 20)\n",
    "axs[2].set_title(\"Histogram on Ambient_temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Distribution of Power Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT power FROM refined_reading\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "power = eventSession.sql(query)\n",
    "power= power.toPandas()\n",
    "power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(16,6))\n",
    "stats.probplot(power.iloc[:,0], plot=plt.subplot(1,3,1))\n",
    "axs[1].boxplot(power.iloc[:,0])\n",
    "axs[1].set_title(\"Boxplot on Power\")\n",
    "axs[2].hist(power.iloc[:,0], bins = 20)\n",
    "axs[2].set_title(\"Histogram on Power\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Distribution of Sensor Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT temperature FROM refined_reading\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "temperature = eventSession.sql(query)\n",
    "temperature= temperature.toPandas()\n",
    "temperature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3, figsize=(16,6))\n",
    "stats.probplot(temperature.iloc[:,0], plot=plt.subplot(1,3,1))\n",
    "axs[1].boxplot(temperature.iloc[:,0])\n",
    "axs[1].set_title(\"Boxplot on Temperature\")\n",
    "axs[2].hist(temperature.iloc[:,0], bins = 20)\n",
    "axs[2].set_title(\"Histogram on Temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- Input-variable vs. Target-variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(16,6))\n",
    "axs[0].scatter(power.iloc[:,0], temperature.iloc[:,0])\n",
    "axs[0].set_xlabel(\"power in kW\")\n",
    "axs[0].set_ylabel(\"temperature in celsius\")\n",
    "axs[0].set_title(\"Power vs. Temperature\")\n",
    "axs[1].scatter(ambient_temp.iloc[:,0], temperature.iloc[:,0])\n",
    "axs[1].set_xlabel(\"ambient_temp in celsius\")\n",
    "axs[1].set_ylabel(\"temperature in celsius\")\n",
    "axs[1].set_title(\"Ambient_temp  vs. Temperature\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**By observing the plots above, we noticed:**\n",
    "- The distribution of power consumption, ambient temperature, and sensor temperature each follows an roughly normal distribution.\n",
    "- The scatter plot shows the sensor temperature has linear relationships with power consumption and ambient temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary\n",
    "This demo introduced you to how to perform data analytics with rich tooling using IBM Db2 Event Store.\n",
    "\n",
    "## Next Step\n",
    "`\"Event_Store_ML_Model_Deployment.ipynb\"` will show you how to build machine learning model and deploy the model with IBM Db2 Event Store."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7 with Watson Studio Spark 2.0.2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
