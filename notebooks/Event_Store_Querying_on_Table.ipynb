{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Querying on IBM Db2 Event Store Database Table\n",
    "IBM Db2 Event Store is a hybrid transactional/analytical processing (HTAP) system that is designed for IoT workloads. It is empowered by the Db2 Common SQL Engine, the most sophisticated SQL-based analytics query engine available. IBM Db2 Event Store can handle complex queries quickly and efficiently.\n",
    "\n",
    "> This Demo is created with IBM Db2 Event Store 2.0 Enterprise edition.\n",
    "\n",
    "In the previous session we have already created a database, a table with an index. We have seen how to ingest sample data into the table in the \"EventStore_Table_Creation\" notebook.\n",
    "\n",
    "***Pre-Req: EventStore_Table_Creation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import event store's Python client interface libraries\n",
    "from eventstore.oltp import EventContext\n",
    "from eventstore.sql import EventSession\n",
    "from pyspark.sql import SparkSession\n",
    "from eventstore.common import ConfigurationReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a id=\"connect-to-es\"></a>\n",
    "### 1. Set up connection to IBM Db2 Event Store\n",
    "\n",
    "**In this demo, we assume your IBM Db2 Event Store is installed with Watson Studio Local (WSL).**\n",
    "\n",
    "You will need to set the Watson Studio Local's `userID` and `password` that will be used to connect to IBM Db2 Event Store instance.\n",
    "\n",
    "By default, the connection will be estabilished to the IBM Db2 Event Store instance on the current Watson Studio Local cluster.\n",
    "\n",
    "For more details on setting up IBM Db2 Event Store connection in Jupyter Notebook, please read the official documentation:\n",
    "https://www.ibm.com/support/knowledgecenter/en/SSGNPV_2.0.0/dsx/jupyter_prereq.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Using the configuration reader API, set up the userID and password that \n",
    "# will be used to connect to IBM Db2 Event Store.\n",
    "\n",
    "ConfigurationReader.setEventUser(\"admin\")\n",
    "ConfigurationReader.setEventPassword(\"password\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Connect to the database\n",
    "**IBM Event Store 2.0 instance will by default have a database created with name `EVENTDB`, and the default database `EVENTDB` should not be deleted. Each IBM Event Store 2.0 instance only support exact ONE database.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dbName = \"EVENTDB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To run Spark SQL queries, you must set up a Db2 Event Store Spark session. SparkSession is the entry point to programming Spark with the Dataset and DataFrame API. The EventSession class extends the optimizer of the SparkSession class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sparkSession = SparkSession.builder.appName(\"EventStore SQL in Python\").getOrCreate()\n",
    "eventSession = EventSession(sparkSession.sparkContext, dbName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now you can execute the command to connect to the database in the event session you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "eventSession.open_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Exploring the database by retrieving all tables\n",
    "With the following cells we can list all user-created tables and explore the schema of the tables we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with EventContext.get_event_context(dbName) as ctx:\n",
    "   print(\"Event context successfully retrieved.\")\n",
    "\n",
    "table_names = ctx.get_names_of_tables()\n",
    "for idx, name in enumerate(table_names):\n",
    "   print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tabName = \"IOT_TEMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tab = eventSession.load_event_table(tabName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's recall the table schema we previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    resolved_table_schema = ctx.get_table(tabName)\n",
    "    print(resolved_table_schema)\n",
    "except Exception as err:\n",
    "    print(\"Table not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's recall that in the previous notebook, the table we created has the following tableSchema and indexSchema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```python\n",
    "tabSchema = TableSchema(tabName, StructType([\n",
    "    StructField(\"DEVICEID\", IntegerType(), nullable = False),\n",
    "    StructField(\"SENSORID\", IntegerType(), nullable = False),\n",
    "    StructField(\"TS\", LongType(), nullable = False),\n",
    "    StructField(\"AMBIENT_TEMP\", DoubleType(), nullable = False),\n",
    "    StructField(\"POWER\", DoubleType(), nullable = False),\n",
    "    StructField(\"TEMPERATURE\", DoubleType(), nullable = False)\n",
    "    ]),\n",
    "    sharding_columns = [\"u'DEVICEID\", \"u'SENSORID\"],\n",
    "    pk_columns = [\"DEVICEID\", \"SENSORID\", \"TS\"]\n",
    "                       )\n",
    "\n",
    "indexSchema = IndexSpecification(\n",
    "          index_name=tabName + \"Index\",\n",
    "          table_schema=tabSchema,\n",
    "          equal_columns = [\"DEVICEID\", \"SENSORID\"],\n",
    "          sort_columns = [\n",
    "            SortSpecification(\"TS\", ColumnOrder.DESCENDING_NULLS_LAST)],\n",
    "          include_columns = [\"TEMPERATURE\"]\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Best Practices for efficient queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 4.1 Basic Event Store queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In the next cell we create a lazily evaluated \"view\" that we can then use similar to a hive table in Spark SQL, but this is only evaluated when we actually run or cache query results. We are calling this view \"readings\" and that is how we will refer to it in the queries below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tab.createOrReplaceTempView(\"readings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT count(*) FROM readings\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "df_data = eventSession.sql(query)\n",
    "df_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's have a look at the record structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM readings LIMIT 1\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "df_data = eventSession.sql(query)\n",
    "df_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT MIN(ts), MAX(ts) FROM readings\"\n",
    "print(\"{}\\nRunning query in Event Store...\".format(query))\n",
    "df_data = eventSession.sql(query)\n",
    "df_data.toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 4.2 Optimal query through the index\n",
    "\n",
    "- Index queries will significantly reduce amount of data that needs to be scanned for results. \n",
    "    - Indexes in IBM Db2 Event Store are formed asynchronously to avoid insert latency. \n",
    "    - They are stored as a Log Structured Merge (LSM) Tree.\n",
    "    - The index is formed by \"runs\", which include sequences of sorted keys. These runs are written to disk during “Share” processing.\n",
    "    - These index runs are merged together over time to improve scan and I/O efficiency.\n",
    "\n",
    "- For an optimal query performance you must specify equality on all the equal_columns in the index and a range on the sort column in the index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For example, in the following query we are retrieving all the values in the range of dates for a specific device and sensor, where both the `deviceID` and `sensorID` are in the equal_columns definition for the index schema and the `ts` column is the sort column for the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "index_query = \"SELECT ts, temperature  FROM readings where deviceID=1 and sensorID=12 and ts >1541021271619 and ts < 1541043671128 order by ts\"\n",
    "print(\"{}\\nCreating a dataframe for the query ...\".format(index_query))\n",
    "df_index_query = eventSession.sql(index_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then the following cell runs the query and caches the results. Note that this caching is for demostration purposes, to show the time it takes to run the query and cache the results in memory within Spark. This caching is recommended when you are going to do additional processing on this cached data, as the query against IBM Db2 Event Store is only run once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_index_query.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Finally the results from the cached data can be visualized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_index_query.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 4.3 Sub-optimal query\n",
    "\n",
    "This next query shows a sub-optimal query that only specifies equality in one of the equal_columns in the index schema, and for this reason ends up doing a full scan of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fullscan_query = \"SELECT count(*)  FROM readings where sensorID = 7\"\n",
    "print(\"{}\\nCreating a dataframe for the query...\".format(fullscan_query))\n",
    "df_fullscan_query = eventSession.sql(fullscan_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_fullscan_query.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_fullscan_query.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 4.4 Accessing multiple sensorIDs optimally\n",
    "\n",
    "The easiest way to write a query that needs to retrieve multiple values in the equal_columns in the index schema is by using an *In-List*. With this, you can get optimal index access across multiple sensorID's. \n",
    "\n",
    "In this example we specify equality for a specific deviceID, and an In-List for the four sensors we are trying to retrieve. To limit the number of records we are returning we also include a range of timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inlist_query = \"SELECT deviceID, sensorID, ts  FROM readings where deviceID=1 and sensorID in (1, 5, 7, 12) and ts >1541021271619 and ts < 1541043671128 order by ts\"\n",
    "print(\"{}\\nCreating a dataframe for the query...\".format(inlist_query))\n",
    "df_inlist_query = eventSession.sql(inlist_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_inlist_query.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_inlist_query.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 4.5 Exploiting the synopsis table:  Advanced medium weight queries\n",
    "\n",
    "- Event Store tables include a synopsis table which summarizes the minimum/maximum values of the data for each range of rows in the synopsis table. \n",
    "\n",
    "     - It contains one range for every 1000 rows.\n",
    "     - It is stored in a separate internal table in the shared storage layer.\n",
    "     - It is parquet compressed to minimize footprint.\n",
    "     - For highly selective queries, it can improve performance by up to 1000x.\n",
    "\n",
    "- Using an equality or a range predicate on a clustered field (e.g. the 'TS' column in our case because the data is inserted into the table in order) is faster than doing a full scan as it should be able to exploit the synopsis table, but this will be slower than an optimal index scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "synopsis_query = \"SELECT deviceID, sensorID, ts FROM readings where ts >1541021271619 and ts < 1541043671128 order by ts\"\n",
    "print(\"{}\\nCreating a dataframe for the query...\".format(synopsis_query))\n",
    "df_synopsis_query = eventSession.sql(synopsis_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_synopsis_query.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_synopsis_query.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Summary\n",
    "This demo introduced you to the best practices querying the table stored in IBM Db2 Event Store database.\n",
    "\n",
    "## Next Step\n",
    "`\"Event_Store_Data_Analytics.ipynb\"` will show you how to perform data analytics with IBM Db2 Event Store with multiple scientific tools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python2.7 with Watson Studio Spark 2.0.2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
